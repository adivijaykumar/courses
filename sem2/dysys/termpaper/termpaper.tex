\documentclass[a4paper,11pt]{article}

\usepackage{physics}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm, mathtools}
%\usepackage{hyperref}
\usepackage{color}
\usepackage{jheppub}
\usepackage[T1]{fontenc} % if needed

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\bes}{\begin{equation*}}
\newcommand{\ees}{\end{equation*}}
\newcommand{\bea}{\begin{flalign*}}
\newcommand{\eea}{\end{flalign*}}

%\linespread{1.0}
%\setlength{\parindent}{0em}
%\setlength{\parskip}{0.8em}

\title{\textbf{Singular Perturbation Theory}}
\author{Aditya Vijaykumar}
\affiliation{International Centre for Theoretical Sciences, Bengaluru, India.}
\emailAdd{aditya.vijaykumar@icts.res.in}
\abstract{Course Project - Dynamical Systems}

\begin{document}
\maketitle
\section{Introduction}
We take a tour of the theory of singular perturbations and the methods to solve them. Main references for the material in this report are :-
\begin{itemize}
\item Bender, Carl M., and Steven A. Orszag. 2013. \textit{Advanced mathematical methods for scientists and engineers}. New York: Springer.
\item O'Malley, Robert E. 2013. \textit{Singular perturbation methods for ordinary differential equations}.  Springer-Verlag New York.
\item Lin, C. C., Lee A. Segel, and G. H. Handelman. 2006. \textit{Mathematics applied to deterministic problems in the natural sciences}. Philadelphia, Pa: Society for Industrial and Applied Mathematics.
\end{itemize}
\section{Singular Perturbation theory for Algebraic Equations}
Consider first the equation $ \epsilon m^2 + 2m + 1 =0 $, where $ \epsilon << 1 $ is a small parameter. We note that with $ \epsilon= 0$ the equation has just one solution $ m = -1/2 $, whereas the full equation has two solutions by virtue of being quadratic. If what we desire are perturbative solutions around the unperturbed solutions, we won't be able to obtain two solutions by usual power series substitution.

So where exactly are we failing to capture the problem? As this problem is exactly solvable, let's look at the roots -
\begin{equation*}
m_\pm = \dfrac{-1 \pm \sqrt{1 - \epsilon}}{\epsilon} \approx\dfrac{-1 \pm (1 - \epsilon/2)}{\epsilon} \approx -\dfrac{1}{2}, - \dfrac{2}{\epsilon}
\end{equation*}
We see that the roots are diverging at $ \epsilon \rightarrow 0 $, which explains why the perturbative approach fails! So  from the two preceding observations that \textit{ignoring} the $ \epsilon $ for obtaining the unperturbed solution is not the best of ideas. 

Let's then try to do the next best thing - trying to see what terms have comparable orders as the $ \epsilon m^2 $ term. We adopt a trial and error approach. Let's first try $ \epsilon m^2 \sim m \implies m \sim \frac{1}{\epsilon} \implies 2m  = \order{\frac{1}{\epsilon}} $. This means that now the $ \epsilon m^2 $ term cannot be ignored. Let's make the substitution $ m = \frac{x}{\epsilon}$ to, in some sense, normalize $ \epsilon  $ term.
\begin{align*}
\implies \epsilon \qty(\dfrac{x}{\epsilon})^2 + 2 \dfrac{x}{\epsilon} + 1 = 0 \\
\implies \dfrac{x^2}{\epsilon} + 2 \dfrac{x}{\epsilon} + 1 = 0 \\
\implies x^2 + 2 x + \epsilon = 0
\end{align*}
Let's make the substitution $  x = \sum_{n=0}^{\infty} x_n \epsilon^n$. Upto first order in $ \epsilon $, we get the following equations,
\begin{align*}
x_0^2 + 2 x_0 = 0 &\implies x_0 = 0 , -2 \\
2 x_0 x_1 + 2 x_1 + 1 = 0 &\implies x_1 = -\dfrac{1}{2}, x_1 = \dfrac{1}{2} \qq{pairwise for } x_0= 0 , -\frac{1}{2}
\end{align*}
Hence we have the two roots, perturbatively to $ \order{\epsilon} $,
\begin{equation*}
x = -\dfrac{\epsilon}{2}, -2 + \dfrac{\epsilon}{2} \implies m = -\dfrac{1}{2}, -\dfrac{2}{\epsilon}
\end{equation*}
So this procedure works! The procedure is actually called the \textit{method of dominant balance}. Let's look at a more complicated equation, $ \epsilon x^4 + \epsilon x^3 - x^2 + 2x - 1 =0 $. A usual characteristic of a singular perturbation problem is that the highest order term is multiplied by an infinitesimal quantity. Let's apply the above procedure to this equation -
\begin{itemize}
	\item Substituting $ x = \sum_{n} a_n \epsilon^n $, we get,
	\begin{align*}
	a_0^2 -2a_0 +1 = 0 \implies a_0 = 1,-1 \\
	a_0^4 +a_0^3 - 2 a_0 a_1 + 2 a_1 = 0 \implies 
	\end{align*}
	\item $ \epsilon x^4 \sim x^2 \implies x \sim \frac{1}{\sqrt{\epsilon}} \sim \frac{1}{\mu} $. Substituting $ x = \frac{m}{\mu} $, $ m^4 + \mu m^3 - m^2 + 2 \mu m - \mu^2 = 0$. Substituting $ m = \sum_{n=0}^{\infty} a_n \mu^n $ and using sympy to do the algebraic manipulations, we get the following equations,
	\begin{align*}
	a_0^4 - a_0^2 = 0 &\implies a_0 = 1,-1 \\
	4 a_0^3 a_1 + a_0^3 - 2 a_0 a_1 + 2 a_0 = 0 &\implies a_1 = -\frac{3}{2}, -\frac{3}{2} \\
	4 a_0^3 a_2 + 6 a_0^2 a_1^2 + 3 a_0^2 a_1 -2 a_0 a_2 - a_1^2 +2 a_1 - 1 = 0 &\implies a_2 = -\dfrac{11}{8}, \dfrac{11}{8}
	\end{align*}
	Hence, we get two roots as,
	\begin{align*}
	x &= \frac{1 -\frac{3}{2}\mu - \frac{11}{8} \mu^2}{\mu}, \frac{-1 -\frac{3}{2}\mu + \frac{11}{8} \mu^2}{\mu} \\
	\implies x &\approx \frac{1}{\sqrt{\epsilon}} -\frac{3}{2}, -\frac{1}{\sqrt{\epsilon}} -\frac{3}{2}
	\end{align*}
	\item $ \epsilon x^4 + \epsilon x^3 = (x-1)^2 \implies x = 1 \pm \sqrt{\epsilon} \sqrt{x^3 + x^4}$. We can use this to set up an iterative scheme in $ \sqrt{\epsilon} $. Therefore, two more roots are,
	\begin{equation*}
	x = 1 + \sqrt{2} \sqrt{\epsilon} + \dfrac{7}{2} \epsilon, 1 - \sqrt{2} \sqrt{\epsilon} + \dfrac{7}{2} \epsilon, 
	\end{equation*}
\end{itemize}
	
\section{Singular Perturbation Theory for Ordinary Differential Equations}
\subsection{Boundary Value Problem}
\begin{equation*}
\epsilon y'' + 2 y' + y = 0 \qq{,} y' = \dv{y}{x} \qq{,} y(0) = 0 \qq{,} y(1)=1
\end{equation*}
The unperturbed differential equation reads $ 2y' + y = 0  $. We see now, if we take both boundary conditions into account, that this is an overdetermined problem. Anyway, this unperturbed equation has the general solution,
\begin{equation*}
y = A \exp(-\dfrac{x}{2}) \implies y = 0 \qq{OR} y = \exp(\dfrac{1-x}{2})
\end{equation*} 
How do we reconcile the differences? Let's first solve the differential equation exactly by substituting $ y = \exp(mx) $ :-
\begin{align*}
\epsilon m^2 + 2m + 1 = 0 &\implies m = \dfrac{-1 \pm \sqrt{1 - \epsilon}}{\epsilon} \approx -\dfrac{1}{2}, -\dfrac{2}{\epsilon} \\
\implies y = B \exp(-\dfrac{x}{2}) +  C \exp(-\dfrac{2x}{\epsilon}) &\implies y \approx e^{1/2} \qty(\exp(-\dfrac{x}{2}) - \exp(-\dfrac{2x}{\epsilon}) )
\end{align*}
So, we see that there is a term which becomes large as $ x\rightarrow 0 $, but dies of faster as $ x $ increases. This infinitesimal region near $x =0 $ is popularly called the the \textit{boundary layer}, mainly inspired by fluid mechanics problems. 

What does this tell us? We can clearly see that there are two regions in the problem - one where the effects of the $ \epsilon $ term are significant, and one where the effects are insignificant. This suggests we should really solve this equation in these regions separately and then adopt some kind of matching procedure. So let's do exactly that, first for the region where $ x \sim \order{\epsilon} $. Substituting $ t = \frac{x}{\delta} $ in the governing equation, we get,
\begin{equation*}
\dfrac{\epsilon}{\delta^2} \ddot{y} + \dfrac{2}{\delta} \dot{y} + y = 0 \qq{,} \dot{y} = \dv{y}{t}
\end{equation*}
Let's now apply a dominant balance like method here. If $ \frac{\epsilon}{\delta^2} \sim \frac{2}{\delta}  \implies \epsilon \sim \delta$, after rearranging terms and neglecting $ \order{\epsilon} $ terms, we have
\begin{equation*}
\ddot{y} + 2 \dot{y} = 0 \implies y = A + B \exp(-2t) 
\end{equation*}
We note that this solution is only valid when $ \delta \sim \epsilon $, \textit{ie} when $ x \rightarrow 0 $. Hence, imposing only the boundary condition $ y(0) = 0 $, we have $ y_{in} = A(1 - e^{-2t}) $. We have already obtained the solution far away from zero, which is just $ y_{out} =e^{\frac{1-x}{2}}  $. So we have now got solutions at two extremities, and need to match these solutions at some intermediate points. If $ \theta(\epsilon) $ is the scale of the intermediate region, we can say it should satisfy the following,
\begin{equation*}
\lim\limits_{\epsilon \rightarrow 0} \dfrac{\theta}{\epsilon} = \infty \qq{and} \lim\limits_{\epsilon \rightarrow 0} \theta = 0
\end{equation*}
So it's natural to now consider another scale in the system $ x \sim \theta $ and substitute $ x = \eta \theta \implies t = \frac{\eta \theta}{\delta}$. Matching condition requires,
\begin{align*}
\lim\limits_{\epsilon \rightarrow 0} y_{out}(x=\eta \theta) &= \lim\limits_{\epsilon \rightarrow 0} y_{in}( x =\eta \theta) \\
\implies \lim\limits_{\epsilon \rightarrow 0}e^{\frac{1 - \eta \theta}{2}} &= \lim\limits_{\epsilon \rightarrow 0}A( 1 - e^{-2 \eta \theta/\delta}) \\
\implies e^{1/2} &= A
\end{align*}
Hence, we can now say that $ y_{in} =   e^{1/2}(1 - e^{-2x/\epsilon})$. To obtain a seemingly uniform solution, what we can do is add the inner and outer solutions and subtract the common part \textit{i.e.} $ e^{1/2} $,
\begin{equation*}
\implies y_{uni} = e^{1/2}(e^{-x/2} - e^{-2x/\epsilon})
\end{equation*}
which exactly agrees with our initial approximation.

This was a problem whose exact solution was known to us. Let's try to do a slightly trickier problem. Consider,
\begin{equation*}
\epsilon y''' - y' + xy = 0 \qq{,} y(0) = y'(0) = y(1)= 1
\end{equation*}
The unperturbed equation has solution $ y_{out} = A_0 e^{x^2/2} $. Let us consider the boundary layer of thickness $ \delta $ near $ x=0 $. Substituting $ t = \frac{x}{\delta} $, the equation becomes,
\begin{align*}
\dfrac{\epsilon}{\delta^3} \dddot{y} - \dfrac{1}{\delta} \dot{y} + xy = 0 &\qq{,} \dfrac{\epsilon}{\delta^3} \sim \dfrac{1}{\delta} \implies \delta \sim \sqrt{\epsilon} \\
\dddot{y} - \dot{y} = 0 \implies \dot{y} = A e^t + B e^{-t} &\implies y_{in} = A e^t - B e^{-t} + C \implies y_{in}' = \dfrac{A}{\sqrt{\epsilon}} e^{\frac{x}{\sqrt{\epsilon}}} + \dfrac{B}{\sqrt{\epsilon}} e^{-\frac{x}{\sqrt{\epsilon}}}
\end{align*}
We now impose boundary conditions $ y(0)= y'(0) = 1 \implies  $ and get $ y_{in}  = A (e^\frac{x}{\sqrt{\epsilon}} + e^{-\frac{x}{\sqrt{\epsilon}}}) + (1- 2A )$, where we have retained only the leading terms. If we try to match the inner and outer solutions, we see that there is now way that the final form of the solution satisfies the boundary condition $ y(1) = 1 $ . Hence we expect to have another layer at $ x=1 $. Now using t = $\frac{1-x}{\delta}$ and doing a similar procedure again, we obtain,
\begin{equation*}
y_{1in} = A' e^{\frac{1-x}{\sqrt{\epsilon}}} + B' e^{-\frac{1-x}{\sqrt{\epsilon}}} + (1 - A' - B')
\end{equation*}
Matching this with the outer solution gives $ A'=0, B'=1, A_0 = 1  \implies y_{out} = e^{x^2/2} $ and $ y_{1in} = e^{\frac{x-1}{\sqrt
\epsilon}} $. The perturbative solution upto leading order is, hence,
\begin{equation*}
y_{uni} = e^{x^2/2} (1 + \sqrt{\epsilon}) + e^{\frac{x-1}{\sqrt{\epsilon}}} (\sqrt{\epsilon }-1) - \sqrt{\epsilon} e^{-\frac{x}{\sqrt{\epsilon}}} + constant
\end{equation*}






\subsection{Initial Value Problem}
We consider a problem which is prevalant in chemical kinetics. without going into the details of it, we note that the governing equations are,
\begin{align*}
\dot{x}=-x + (x + \kappa - \lambda )y \qq{,} x(0)=1\\
\epsilon \dot{y} = x - (x + \kappa )y \qq{,} y(0)=0
\end{align*}
Here, $ \epsilon $ is typically $ \order{10^{-6}} $, and $ \kappa, \lambda $ are positive constants. The unperturbed equation is,
\begin{align*}
0 = x - (x + \kappa )y  &\implies y_{out} = \dfrac{x_{out}}{x_{out}+ \kappa}\\
\dot{x}=-x + (x + \kappa - \lambda )y = -\dfrac{\lambda x}{x + \kappa} &\implies x_{out} + \kappa \log x_{out} = - \lambda t + C 
\end{align*}

To get a perturbative solution, we take inspiration from the boundary layer problems and say that there should be a initial time layer of thickness $ \delta $. Hence, changing variables $ \tau = t/\delta $, we see, with $ x' = \dv{x}{\tau} $,
\begin{equation*}
\dfrac{1}{\delta} x' = -x + (x + \kappa - \lambda )y \qq{and} \dfrac{\epsilon}{\delta} y' = x - (x + \kappa) y  
\end{equation*}
Comparing scales, we see that $ \delta \sim \epsilon $, and hence
\begin{align*}
 x' = -\epsilon x + \epsilon (x + \kappa - \lambda )y \qq{and} y' = x - (x + \kappa) y  
\end{align*}
As the boundary layer is near $ t = \tau = 0 $, the boundary conditions $ x(0)=1, y(0)=0  $ should be satisfied inside the boundary layer. Solving the above equations,
\begin{equation*}
x_{in } =1 \qq{and} y_{in} = \dfrac{1 - e^{- (\kappa + 1) t/\epsilon}}{\kappa + 1}
\end{equation*}

We now need to match solutions at intermediate times. Let $ \eta  $ be our matching scale in $ t $. Here,
\begin{equation*}
\lim\limits_{\epsilon \rightarrow 0} \dfrac{\eta}{\epsilon} = \infty \qq{and} \lim\limits_{\epsilon \rightarrow 0} \eta = 0
\end{equation*}
Matching the $ x$ solutions, we get $ C=1 $. To obtain the \textit{uniform solution}, we again add the inner and outer solutions and subtract the common part. Therefore,
\begin{align*}
x_{uni} = 1 + x_{out} -1 = x_{out} \\
y_{uni} = \dfrac{1 - e^{- (\kappa + 1) t/\epsilon}}{\kappa + 1} + \dfrac{x_{out}}{x_{out} + \kappa}
\end{align*}
where $ x_{out} $ is given implicitly as stated before.








\section{Method of Multiple Scales}
Consider the damped harmonic oscillator with the following governing equation,
\begin{equation*}
\ddot{x} + 2 \epsilon \dot{x} + x = 0 \qq{,}  x(0) = 0 \qq{,} \dot{x}(0) = 1 \implies x(t) = e^{-\epsilon t} \dfrac{\sin(t \sqrt{1-\epsilon^2})t}{\sqrt{1-\epsilon^2}}
\end{equation*}
We can see in this solution that there are two timescales governing the variation in the solution. One is the \textit{slow} timescale $ \tau = \epsilon t $ during which the solution has an exponential decay, and the other is the \textit{fast} timescale $ T = t \sqrt{1 - \epsilon^2} $ in which the solution varies sinusoidally. We could say then that a formulation of the problem should exist in $ \tau, T, \epsilon $. This is the philosophy behind the method of multiple scales.

We could solve this damped harmonic oscillator problem by multiple scales, but since it is easy and exactly solvable, let us look at a somewhat more complicated \textit{non-linear} equation namely the Duffing equation with damping given by,
\begin{equation*}
\ddot{x} + x + \epsilon(2 \lambda \dot{x} - x^3) = 0 \qq{,} x(0)=1 \qq{,} \dot{x}(0) = 0 
\end{equation*}
We introduce two timescales into this problem,
\begin{equation*}
\tau = \epsilon t \qq{and} T = \qty(1 + \sum_{n=2}^\infty \epsilon^n \omega_n ) t \qq{and also} x(t) = X(\tau,T, \epsilon) = \sum_{n=0}^{\infty} \epsilon^n X_n(\tau,T)
\end{equation*}
As we have changed the timescales, we need to rewrite the time derivatives in the governing equation,
\begin{align*}
\dv{t} = \epsilon \dv{\tau} &+ \qty(1 + \sum_{n=2}^\infty \epsilon^n \omega_n )\dv{T} \\
\implies \epsilon^2 X_{\tau \tau} + \qty(1 + \sum_{n=2}^\infty \epsilon^n \omega_n )^2 X_{TT} &+ 2 \epsilon \qty(1 + \sum_{n=2}^\infty \epsilon^n \omega_n ) X_{T \tau} + 
\\2 \epsilon \lambda \qty[\epsilon X_\tau + \qty(1 + \sum_{n=2}^\infty \epsilon^n \omega_n ) X_{T}]  &- \epsilon X^3 = 0 
\end{align*}
Substituting expansion for $ X $ in the second equation above, one obtains the following,
\begin{align*}
X_{0TT} + X_0 = 0 \qq{,} X_{1TT}  + X_1 + 2 X_{0T \tau} + 2 \lambda X_{0T} - X_0^3 = 0 \\
X_{2TT} + X_2 + 2 \omega_2 X_{0TT} + 2 X_{1 T \tau} + X_{0 \tau \tau } + 2 \lambda (X_{1T} + X_{0 \tau}) - 3 X_0^2 X_1 = 0
\end{align*}
The initial conditions in terms of $ X, \dot{X}$ become,
\begin{align*}
X_0(0,0) = 1 &\qq{,} X_n(0,0 ) = 0 , \forall n \ne 0 \\
X_{0T}(0,0) = X_{0 \tau}(0,0) + X_{1 T}(0,0) &= X_{2T}(0,0) + \omega_2 X_{0T}(0,0) + X_{1T}(0,0) = 0 
\end{align*}
Solving the first differential equation for $ X_0 $ and applying appropriate boundary conditions, we get,
\begin{equation*}
X_0(T, \tau) = A_0(\tau) \cos(T + \phi_0(\tau))  \qq{,} A_0(0) = 1 \qq{,} \phi_0( 0) = 0 
\end{equation*}
With this solution, we can write the equation for $ X_1 $ as (with $ \theta_0 = T + \phi_0 $),
\begin{align*}
X_{1TT} + X_1 -2 A_0'\sin \theta_0 -2 A_0 \phi_0' \sin \theta_0 + 2 \lambda A_0 \sin \theta_0 - A_0^3 \cos^3\theta_0 = 0 \\
X_{1TT} + X_1 -2 A_0'\sin \theta_0 -2 A_0 \phi_0' \cos \theta_0 - 2 \lambda A_0 \sin \theta_0 - A_0^3 \dfrac{\cos 3\theta_0}{4} - 3A_0^3 \dfrac{\cos \theta_0}{4}   = 0 
\end{align*}
Now, we want an overall periodic solution for $ X $, and hence $ X_1 $ should also exhibit periodic behaviour. For this to hold,
\begin{equation*}
A_0' + \lambda A_0 = 0 \qq{and} \phi_0' = - \dfrac{3}{8} A_0^2 \implies A_0 = e^{-\lambda \tau} \qq{and} \phi_0 = \dfrac{3}{16 \lambda} ( 1 - e^{-2 \lambda \tau})
\end{equation*}
With these substitutions, $ X_1 $ becomes,
\begin{equation*}
X_1(T,\tau) = A_1(\tau) \cos (T + \phi_1(\tau) ) + \dfrac{1}{32} e^{-3 \lambda \tau} \cos(3\{T + \phi_0(\tau)\})
\end{equation*}
The boundary conditions for $ X_1  $ are $ X_1(0,0)= 0 , X_{1T}(0,0) = - A'(0) $. Substituting gives,
\begin{equation*}
A_1(0) \cos(\phi_1(0)) = -\dfrac{1}{32} \qq{and} A_1(0) \sin(\phi_1(0)) = \lambda 
\end{equation*}
Similarly, we substitute $ X_1 , X_0 $ in the equation for $ X_2 $. The calculations are long, but the conclusion derived after all that is $ \omega_2 = -\frac{1}{\lambda^2} $. So finally, we have out answer,
\begin{equation*}
x \sim e^{-\lambda\tau} \cos\qty[T + \dfrac{3}{16 \lambda}(1- e^{-2 \lambda \tau})] + \epsilon \qty{ A_1(\tau) \cos(T + \phi_1(\tau)) + \dfrac{1}{32} e^{-3 \lambda \tau}  \cos\qty[3T + \dfrac{9}{16 \lambda}(1- e^{-2 \lambda \tau}) ]}
\end{equation*}

We can apply this method to a whole range of differential equations.
\end{document}




